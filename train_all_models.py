#!/usr/bin/env python

from datetime import datetime
from itertools import imap
import os
import glob
import predict_this.text.text as Text
import predict_this.flm.flm_specification as FlmSpec

LOG_FILENAME = "training.log"

log_file = open(LOG_FILENAME, "a")


def now():
    return datetime.now().strftime('%Y-%m-%d %H:%M:%S')


def log(s):
    print >>log_file, now(), ":", s


def dump_training_file(flm_spec, output_file):
    for i in xrange(2500):
        index = str(i).zfill(4)
        tagged_filename = "corpus/resultados/analisis_%s.txt.ascii" % index
        tagged_text = Text.Text.from_freeling_output_file(tagged_filename)
        # use tmpfiles....
        with open(tagged_filename + ".factored", "w") as factored_file:
            for tagged_line in tagged_text.lines():
                factored_file.write(" ".join(map(flm_spec.convert_to_flm_format, tagged_line)) + "\n")
    os.system("./concatenate_files.sh corpus/resultados/ \"*.factored\" " + output_file)


with open("train_all_models.sh", "w") as training_script:
    print >>training_script, "#!/usr/bin/env bash\n"
    print >>training_script, "# AUTOGENERATED SCRIPT at %s \n" % now()

    for flm_model_filename in glob.glob("flm_models/*.flm"):
        log("factoring text for " + flm_model_filename)

        factored_file_filename = flm_model_filename + ".factored"
        flm_spec = FlmSpec.FLM_Specification(flm_model_filename)
        dump_training_file(flm_spec, factored_file_filename)

        print >>training_script, "echo \"$(date): training %s\" >> %s" % (flm_model_filename, LOG_FILENAME)
        print >>training_script, "fngram-count -factor-file %s -no-virtual-end-sentence -lm -write-counts -text %s" % \
            (flm_model_filename, factored_file_filename)

        log("done factoring text for " + flm_model_filename)

    print >>training_script, "echo \"$(date): finished training\" >>", LOG_FILENAME
log("done facotring and creating script for training")

print "Factored files, prepared script for training."
print "To continue training execute ./train_all_models.sh"
